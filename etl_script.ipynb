{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import boto3\n",
    "from io import BytesIO\n",
    "import gzip\n",
    "import psycopg2\n",
    "from datetime import datetime\n",
    "from dateutil.parser import parse\n",
    "import logging\n",
    "import credss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: 1 rows have invalid dates in column D.O.D.\n"
     ]
    }
   ],
   "source": [
    "# Read the CSV \n",
    "adm_df = pd.read_csv('Admission Data.csv')\n",
    "mort_df = pd.read_csv('Mortality Data.csv')\n",
    "poll_df = pd.read_csv('Pollution Data.csv')\n",
    "\n",
    "## Print the resulting DataFrame\n",
    "# print(adm_df.head(50))\n",
    "# print(mort_df.head(50))\n",
    "# print(poll_df.head(50))\n",
    "\n",
    "## Check for missing values and drop them\n",
    "\n",
    "# adm_df.isnull().sum()\n",
    "\n",
    "# mort_df.isnull().sum()\n",
    "\n",
    "# poll_df.isnull().sum()\n",
    "\n",
    "\n",
    "adm_df.fillna(0, inplace=True)\n",
    "\n",
    "\n",
    "poll_df = poll_df.dropna()\n",
    "\n",
    "\n",
    "\n",
    "# # Identify duplicate rows\n",
    "# duplicateRows = adm_df[adm_df.duplicated()]\n",
    "# print(duplicateRows)\n",
    "# duplicateRows = mort_df[adm_df.duplicated()]\n",
    "# print(duplicateRows)\n",
    "# duplicateRows = adm_df[adm_df.duplicated()]\n",
    "# print(duplicateRows)\n",
    "\n",
    "\n",
    "\n",
    "# Changing column to date format\n",
    "\n",
    "\n",
    "def time_format(df: pd.DataFrame, col: str) -> pd.DataFrame:\n",
    "    def parse_with_dayfirst(date_str):\n",
    "        if pd.isna(date_str):\n",
    "            return pd.NaT\n",
    "        try:\n",
    "            # Try parsing with month first (default behavior)\n",
    "            return parse(date_str)\n",
    "        except ValueError:\n",
    "            try:\n",
    "                # If month first fails, try with day first\n",
    "                return parse(date_str, dayfirst=True)\n",
    "            except ValueError:\n",
    "                # If both fail, return NaT\n",
    "                return pd.NaT\n",
    "\n",
    "    # Apply the parsing function and ensure the result is datetime\n",
    "    df[col] = pd.to_datetime(df[col].apply(parse_with_dayfirst), errors='coerce')\n",
    "\n",
    "    # Identify rows with invalid dates\n",
    "    invalid_dates = df[df[col].isna()]\n",
    "    if not invalid_dates.empty:\n",
    "        print(f\"Warning: {len(invalid_dates)} rows have invalid dates in column {col}.\")\n",
    "        # print(invalid_dates)\n",
    "\n",
    "    # Check if all values are NaT\n",
    "    if df[col].isna().all():\n",
    "        # print(f\"Error: All values in column {col} are invalid dates.\")\n",
    "        \n",
    "        # 1. Fill with a default date\n",
    "        df[col] = pd.to_datetime('2000-01-01')\n",
    "        # 2. Fill with the current date\n",
    "        # df[col] = pd.to_datetime(datetime.now().date())\n",
    "        # 3. Or just return the DataFrame with NaT values\n",
    "        return df\n",
    "\n",
    "    # Convert datetime values to strings in the desired format\n",
    "    df[col] = df[col].dt.strftime('%Y-%m-%d')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "adm_df = time_format(adm_df, 'D.O.A')\n",
    "adm_df = time_format(adm_df, 'D.O.D')\n",
    "adm_df = adm_df.dropna()\n",
    "\n",
    "adm_values_to_drop = [3253, 4053, 4357, 4572, 4622, 10165]\n",
    "adm_df = adm_df.drop(adm_df[adm_df['SNO'].isin(adm_values_to_drop)].index)\n",
    "\n",
    "# # print(adm_df.head(50))\n",
    "\n",
    "mort_df = time_format(mort_df, 'DATE OF BROUGHT DEAD')\n",
    "\n",
    "# # print(mort_df.head(50))\n",
    "\n",
    "poll_df = time_format(poll_df, 'DATE')\n",
    "poll_values_to_drop = ['2018-11-16', '2019-01-23']\n",
    "poll_df = poll_df.drop(poll_df[poll_df['DATE'].isin(poll_values_to_drop)].index)\n",
    "# # print(poll_df.head(50))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SNO                                0\n",
       "MRD No.                            0\n",
       "D.O.A                              0\n",
       "D.O.D                              0\n",
       "AGE                                0\n",
       "GENDER                             0\n",
       "RURAL                              0\n",
       "TYPE OF ADMISSION-EMERGENCY/OPD    0\n",
       "month year                         0\n",
       "DURATION OF STAY                   0\n",
       "duration of intensive unit stay    0\n",
       "OUTCOME                            0\n",
       "SMOKING                            0\n",
       "ALCOHOL                            0\n",
       "DM                                 0\n",
       "HTN                                0\n",
       "CAD                                0\n",
       "PRIOR CMP                          0\n",
       "CKD                                0\n",
       "HB                                 0\n",
       "TLC                                0\n",
       "PLATELETS                          0\n",
       "GLUCOSE                            0\n",
       "UREA                               0\n",
       "CREATININE                         0\n",
       "BNP                                0\n",
       "RAISED CARDIAC ENZYMES             0\n",
       "EF                                 0\n",
       "SEVERE ANAEMIA                     0\n",
       "ANAEMIA                            0\n",
       "STABLE ANGINA                      0\n",
       "ACS                                0\n",
       "STEMI                              0\n",
       "ATYPICAL CHEST PAIN                0\n",
       "HEART FAILURE                      0\n",
       "HFREF                              0\n",
       "HFNEF                              0\n",
       "VALVULAR                           0\n",
       "CHB                                0\n",
       "SSS                                0\n",
       "AKI                                0\n",
       "CVA INFRACT                        0\n",
       "CVA BLEED                          0\n",
       "AF                                 0\n",
       "VT                                 0\n",
       "PSVT                               0\n",
       "CONGENITAL                         0\n",
       "UTI                                0\n",
       "NEURO CARDIOGENIC SYNCOPE          0\n",
       "ORTHOSTATIC                        0\n",
       "INFECTIVE ENDOCARDITIS             0\n",
       "DVT                                0\n",
       "CARDIOGENIC SHOCK                  0\n",
       "SHOCK                              0\n",
       "PULMONARY EMBOLISM                 0\n",
       "CHEST INFECTION                    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adm_df.isnull().sum()\n",
    "\n",
    "# mort_df.isnull().sum()\n",
    "\n",
    "# poll_df.isnull().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessed file\n",
    "\n",
    "adm_df.to_csv('admission_data.csv', index=False, header=True, sep=',')\n",
    "\n",
    "mort_df.to_csv('mortality_data.csv', index=False, header=True, sep=',')\n",
    "\n",
    "poll_df.to_csv('pollution_data.csv', index=False, header=True, sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uploaded admission_data.csv to hospital-admiss\n",
      "Uploaded mortality_data.csv to hospital-admiss\n",
      "Uploaded pollution_data.csv to hospital-admiss\n"
     ]
    }
   ],
   "source": [
    "# Persist data in S3 bucket\n",
    "s3 = boto3.client('s3')\n",
    "bucket_name = credss.bucket_name\n",
    "file_name = [\"admission_data.csv\", \"mortality_data.csv\", \"pollution_data.csv\"]\n",
    "\n",
    "for local_file in file_name:\n",
    "    s3.upload_file(local_file, bucket_name, local_file)\n",
    "    print(f\"Uploaded {local_file} to {bucket_name}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Getting column names to build table\n",
    "\n",
    "# column_names = list(adm_df.columns)\n",
    "# for column in column_names:\n",
    "#     print(column)\n",
    "\n",
    "# column_names = list(mort_df.columns)\n",
    "# for column in column_names:\n",
    "#     print(column)\n",
    "\n",
    "# column_names = list(poll_df.columns)\n",
    "# for column in column_names:\n",
    "#     print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redshift Connection\n",
    "try:\n",
    "    con = psycopg2.connect(dbname=credss.dbname,\n",
    "                        host=credss.host,\n",
    "                        port=credss.port,\n",
    "                        user=credss.user,\n",
    "                        password=credss.password)\n",
    "    logging.info('Redshift connection succeeded')\n",
    "except Exception as e:\n",
    "    logging.exception(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "con.autocommit = True\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data into hospital_data.admission_data: syntax error at or near \"arn\"\n",
      "LINE 4:             IAM_ROLE arn:aws:iam::975050149002:role/service-...\n",
      "                             ^\n",
      "\n",
      "Error loading data into hospital_data.mortality_data: syntax error at or near \"arn\"\n",
      "LINE 4:             IAM_ROLE arn:aws:iam::975050149002:role/service-...\n",
      "                             ^\n",
      "\n",
      "Error loading data into hospital_data.pollution_data: syntax error at or near \"arn\"\n",
      "LINE 4:             IAM_ROLE arn:aws:iam::975050149002:role/service-...\n",
      "                             ^\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data to redshift\n",
    "def load_data_to_redshift(schema_name, table_name, s3_location):\n",
    "    \"\"\"\n",
    "    Loads data from an S3 location into a Redshift table.\n",
    "\n",
    "    Args:\n",
    "        schema_name (str): Name of the Redshift schema.\n",
    "        table_name (str): Name of the target table.\n",
    "        s3_location (str): S3 location of the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    try:\n",
    "        copy_query = f\"\"\"\n",
    "            COPY {schema_name}.{table_name}\n",
    "            FROM '{s3_location}'\n",
    "            IAM_ROLE {credss.IAM_ROLE}\n",
    "            CSV\n",
    "            IGNOREHEADER 1;\n",
    "        \"\"\"\n",
    "        cur.execute(copy_query)\n",
    "        print(f\"Data loaded into {schema_name}.{table_name} successfully.\")\n",
    "    except psycopg2.Error as e:\n",
    "        print(f\"Error loading data into {schema_name}.{table_name}: {e}\")\n",
    "\n",
    "\n",
    "schema_name = 'hospital_data'\n",
    "load_data_to_redshift(schema_name, 'admission_data', credss.s3_admin)\n",
    "load_data_to_redshift(schema_name, 'mortality_data', credss.s3_hosp)\n",
    "load_data_to_redshift(schema_name, 'pollution_data', credss.s3_poll)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
